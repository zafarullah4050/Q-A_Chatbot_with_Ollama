# Q-A_Chatbot_with_Ollama
# ğŸ¤– Q&A Chatbot with Ollama (Local LLMs)

This project is a Q&A chatbot built using **LangChain**, **Streamlit**, and **Ollama** to run **open-source local LLMs** like Mistral, LLaMA 3, and Gemma. The chatbot provides intelligent answers to user questions specifically about the **LangChain project**.

---

## ğŸš€ Features

- âœ… Uses **local open-source models** via Ollama (no OpenAI key needed!)
- ğŸ¤– Supports multiple models: `mistral`, `gemma:2b`, `llama3`, `llama3:8b`, `llama3:70b`
- ğŸŒ¡ï¸ Adjustable temperature and max token settings
- ğŸ“¦ Clean Streamlit UI
- ğŸ“ˆ LangSmith integration for tracking (optional)

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **Streamlit** â€“ for interactive web UI  
- **LangChain** â€“ to structure prompt and response chains  
- **Ollama** â€“ for running LLMs locally
